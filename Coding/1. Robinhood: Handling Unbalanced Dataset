Robinhood: Say your are building a binary classifier for an unbalanced dataset (where one class is much rarer than the other, say 1% and 99%, respectively). How do you handle this situation?

There are a few approaches to deal with unbalanced classes:

1. Getting More Data
First and foremost thing to assure data authenticity and consistency, it is necessary to acquire more data points that can be added into the original datasets. However, it is sometimes very expansive or difficult to obtain any more data.

2. Changing Accuracy Metrics from Accuracy to Precision, Recall, F1 Score, and the ROC Curve
Accuracy will become less predictive when the data points fed into the accuracy metrics are imbalanced. Therefore, confusion matrix will reflect on more nuanced results of the model performance. 
For example, precision would show what proportion of predicted positives was actually positive. Sensitivity (or is called Recall) would show the proportion of actual positives was actually positive. 
Then specificity demonstrates the proportion of actual negatives that is actually negative where as negative predictive values provides the percentage of predicted negatives that are actually negative.
To sum up the the formula for calculating the elements in a confusion matrix, please refer to the table below.

3. Using Resampling Techniques
Based on the level of imbalance, either oversampling the rare observations or undersamling the rich observations should be applied. However, discretion must be raised when certain events happen rarely which makes the model better off to remain as imbalanced. Refer to appropriate evaluation function for accurate results.

4. Generating Synthetic Data Points
In cases where synthetic data points come into play, SMOTE is a technique to generate more rare-class data points for oversampling purpose.

5. Adopting Ensemble Models
It is also beneficial to assign some proportion of the data points based on classes to run on different ensemble models. For logistic regression which works well on imbalanced datasets, threshold should be adjusted accordingly.

6. Customize Cost Function
A complex way to adopt when resampling is not able to apply is to redesign a proper penalty system for the machine learning model.
